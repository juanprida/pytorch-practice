{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-16T20:08:23.088793Z","iopub.execute_input":"2022-10-16T20:08:23.089209Z","iopub.status.idle":"2022-10-16T20:08:23.118386Z","shell.execute_reply.started":"2022-10-16T20:08:23.089126Z","shell.execute_reply":"2022-10-16T20:08:23.117392Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/dogs-vs-cats/test1.zip\n/kaggle/input/dogs-vs-cats/train.zip\n/kaggle/input/dogs-vs-cats/sampleSubmission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import zipfile\nimport glob\nimport os\nimport PIL\nimport cv2\nfrom PIL import Image\nimport shutil\nfrom tqdm import tqdm\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as T\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-10-16T21:35:45.757748Z","iopub.execute_input":"2022-10-16T21:35:45.758166Z","iopub.status.idle":"2022-10-16T21:35:45.769682Z","shell.execute_reply.started":"2022-10-16T21:35:45.758130Z","shell.execute_reply":"2022-10-16T21:35:45.768653Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"with zipfile.ZipFile('/kaggle/input/dogs-vs-cats/train.zip',\"r\") as train_bkp:\n    train_bkp.extractall()\n\nwith zipfile.ZipFile('/kaggle/input/dogs-vs-cats/test1.zip',\"r\") as test:\n    test.extractall()","metadata":{"execution":{"iopub.status.busy":"2022-10-16T20:08:25.646059Z","iopub.execute_input":"2022-10-16T20:08:25.646616Z","iopub.status.idle":"2022-10-16T20:08:42.852775Z","shell.execute_reply.started":"2022-10-16T20:08:25.646578Z","shell.execute_reply":"2022-10-16T20:08:42.851807Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_path = glob.glob(\"./train/*\")\nprint(len(train_path))\n\ntest_path = glob.glob(\"./test1/*\")\nprint(len(test_path))","metadata":{"execution":{"iopub.status.busy":"2022-10-16T20:08:42.854422Z","iopub.execute_input":"2022-10-16T20:08:42.854809Z","iopub.status.idle":"2022-10-16T20:08:42.962998Z","shell.execute_reply.started":"2022-10-16T20:08:42.854774Z","shell.execute_reply":"2022-10-16T20:08:42.962103Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"25000\n12500\n","output_type":"stream"}]},{"cell_type":"code","source":"target_list = []\nfor sample in train_path:\n    target = os.path.basename(os.path.normpath(sample)).split(\".\")[0]\n    target_list.append(target)","metadata":{"execution":{"iopub.status.busy":"2022-10-16T20:08:42.964326Z","iopub.execute_input":"2022-10-16T20:08:42.964613Z","iopub.status.idle":"2022-10-16T20:08:43.040449Z","shell.execute_reply.started":"2022-10-16T20:08:42.964588Z","shell.execute_reply":"2022-10-16T20:08:43.039620Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"os.makedirs(\"./data_train\")\nos.makedirs(\"./data_train/cat\")\nos.makedirs(\"./data_train/dog\")","metadata":{"execution":{"iopub.status.busy":"2022-10-16T20:08:43.043367Z","iopub.execute_input":"2022-10-16T20:08:43.043845Z","iopub.status.idle":"2022-10-16T20:08:43.050494Z","shell.execute_reply.started":"2022-10-16T20:08:43.043815Z","shell.execute_reply":"2022-10-16T20:08:43.049498Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dogs = 0\ncats = 0\nsource =\"./train_bkp\"\ndog_folder =\"./data_train/dog\"\ncat_folder = \"./data_train/cat\"\n\nfor f,i in zip(train_path, target_list):\n    img= Image.open(f)\n    img = np.array(img)\n    im = cv2.resize(img,(150,150),interpolation=cv2.INTER_LINEAR)\n    rescaled_img = (np.maximum(im,0)/im.max())*255\n    fin_img = np.uint8(rescaled_img)\n    fin_img = Image.fromarray(fin_img)\n    name = i\n    fin_img.save(f)\n    new_path =f\n    if name=='dog':\n        src_path = new_path\n        dst_path = dog_folder\n        shutil.move(src_path, dst_path)\n        dogs+=1\n    else:\n        src_path = new_path\n        dst_path = cat_folder\n        shutil.move(src_path, dst_path)\n        cats+=1","metadata":{"execution":{"iopub.status.busy":"2022-10-16T20:08:43.051905Z","iopub.execute_input":"2022-10-16T20:08:43.052367Z","iopub.status.idle":"2022-10-16T20:10:27.961814Z","shell.execute_reply.started":"2022-10-16T20:08:43.052331Z","shell.execute_reply":"2022-10-16T20:10:27.960698Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"head = './data_train'\nsamples, targets = [], []\nfor n, categorie in enumerate(['cat', 'dog']):\n     files = [f'{head}/{categorie}/{x}' for x in os.listdir(f'{head}/{categorie}')]\n     print(f'{categorie}s: {len(files)}')\n     samples += files\n     targets += [n for i in files]","metadata":{"execution":{"iopub.status.busy":"2022-10-16T20:10:27.963459Z","iopub.execute_input":"2022-10-16T20:10:27.963935Z","iopub.status.idle":"2022-10-16T20:10:27.990798Z","shell.execute_reply.started":"2022-10-16T20:10:27.963896Z","shell.execute_reply":"2022-10-16T20:10:27.989838Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"cats: 12500\ndogs: 12500\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-10-16T20:10:27.992353Z","iopub.execute_input":"2022-10-16T20:10:27.992759Z","iopub.status.idle":"2022-10-16T20:10:28.073009Z","shell.execute_reply.started":"2022-10-16T20:10:27.992720Z","shell.execute_reply":"2022-10-16T20:10:28.071932Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n\n    def __init__(\n        self,\n        image_paths: list,\n        targets: list,\n        transform: bool):\n        \"\"\"\n        Parameters\n        ----------\n        image_paths : list\n            List containing paths to images.\n        targets: list\n            List containing targets.\n        transform: bool\n            If true, perform set of transformations to input data.\n        \"\"\"\n        self.image_paths = image_paths\n        self.targets = targets\n        self.transform = transform\n\n    def __len__(self):\n        \"\"\"Return total number of samples in the dataset.\"\"\"\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):\n        \"\"\"For a given item, returns data corresponding to that index.\n        \n        Parameters\n        ----------\n\n        \"\"\"\n        image = Image.open(self.image_paths[item])\n        # image = cv2.imread(self.image_paths[item])\n        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        # augmented = self.augmentations(image=image)\n        # image = np.transpose(image, (2,0,1)).astype(float)\n\n        transforms = T.Compose([T.ToTensor(), T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n        image = transforms(image)\n\n        target = torch.tensor(self.targets[item])\n        \n        return {\n            'image': image,\n            'target': target\n        }","metadata":{"execution":{"iopub.status.busy":"2022-10-16T20:10:28.076537Z","iopub.execute_input":"2022-10-16T20:10:28.076831Z","iopub.status.idle":"2022-10-16T20:10:28.088624Z","shell.execute_reply.started":"2022-10-16T20:10:28.076799Z","shell.execute_reply":"2022-10-16T20:10:28.087631Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class KittenModel(nn.Module):\n\n    def __init__(self):\n        super(KittenModel, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, 3)\n        self.conv2 = nn.Conv2d(32, 64, 3)\n        self.conv3 = nn.Conv2d(64, 128, 3)\n        self.conv4 = nn.Conv2d(128, 128, 3)\n        \n        self.max_pooling = nn.MaxPool2d((2,2))\n        self.fc1 = nn.Linear(6272, 512)\n        self.fc2 = nn.Linear(512, 2)\n        self.classifier = nn.Softmax(dim=1)\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = self.max_pooling(x)\n\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = self.max_pooling(x)\n\n        x = self.conv3(x)\n        x = F.relu(x)\n        x = self.max_pooling(x)\n\n        x = self.conv4(x)\n        x = F.relu(x)\n        x = self.max_pooling(x)\n\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        X = F.relu(x)\n        x = self.fc2(x)\n        x = self.classifier(x)\n            \n        return x","metadata":{"execution":{"iopub.status.busy":"2022-10-16T20:10:28.090140Z","iopub.execute_input":"2022-10-16T20:10:28.090902Z","iopub.status.idle":"2022-10-16T20:10:28.101895Z","shell.execute_reply.started":"2022-10-16T20:10:28.090866Z","shell.execute_reply":"2022-10-16T20:10:28.100846Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n## First model\nclass scratch_nn(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=100, kernel_size=5, stride=1, padding=0)\n        self.conv2 = nn.Conv2d(100, 200, 3, stride=1, padding=0)\n        self.conv3 = nn.Conv2d(200, 400, 3, stride=1, padding=0)\n        self.mpool = nn.MaxPool2d(kernel_size=3)\n        self.relu = nn.ReLU()\n        self.linear1 = nn.Linear(6400,1024)\n        self.linear2 = nn.Linear(1024,512)\n        self.linear3 = nn.Linear(512,2)\n        self.classifier = nn.Softmax(dim=1)\n        \n    def forward(self,x):\n        x = self.mpool( self.relu(self.conv1(x)) )\n        x = self.mpool( self.relu(self.conv2(x)) )\n        x = self.mpool( self.relu(self.conv3(x)) )\n        x = torch.flatten(x, start_dim=1)\n        x = self.linear1(x)\n        x = self.linear2(x)\n        x = self.linear3(x)\n        x = self.classifier(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-10-16T20:10:28.104621Z","iopub.execute_input":"2022-10-16T20:10:28.105602Z","iopub.status.idle":"2022-10-16T20:10:28.115661Z","shell.execute_reply.started":"2022-10-16T20:10:28.105564Z","shell.execute_reply":"2022-10-16T20:10:28.115008Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class Optimization:\n\n    def __init__(self, model, loss_fn, optimizer):\n        self.model = model\n        self.loss_fn = loss_fn\n        self.optimizer = optimizer\n        self.train_losses = []\n        self.val_losses = []\n        self.val_accuracy = []\n\n    def train_step(self, x, y):\n        \n        # Set model to train.\n        self.model.train()\n        # Predict.\n        yhat = self.model(x)\n        # Compute loss.\n        loss = self.loss_fn(yhat, y)\n        # Backward pass.\n        loss.backward()\n        # Updates parameters.\n        self.optimizer.step()\n        self.optimizer.zero_grad()\n        return loss.item()\n\n    def train(self, train_loader, val_loader, n_epochs):\n        for epoch in range(n_epochs):\n            batch_losses = []\n            for batch in tqdm(train_loader):\n                x, y = batch.values()\n                x = x.to(device)\n                y = y.to(device)\n                loss = self.train_step(x, y)\n                batch_losses.append(loss)\n            epoch_loss = np.mean(batch_losses)\n            self.train_losses.append(epoch_loss)\n\n            with torch.no_grad():\n                self.model.eval()\n                batch_losses_val = []\n                batch_acc_val = []\n                for batch in tqdm(val_loader):\n                    x_val, y_val = batch.values()\n                    x_val = x_val.to(device)\n                    y_val = y_val.to(device)\n                    yhat_val = self.model(x_val)\n                    loss_val = self.loss_fn(yhat_val, y_val)\n                    \n                    y_hat_1d = torch.argmax(yhat_val, dim=1)\n                    acc_val = accuracy_score([int(i) for i in yhat_val[:,1].cpu().numpy()], y_val.cpu().numpy())\n                    \n                    batch_losses_val.append(loss_val.item())\n                    batch_acc_val.append(acc_val)\n                    \n                epoch_loss_val = np.mean(batch_losses_val)\n                epoch_acc_val = np.mean(batch_acc_val)\n                self.val_losses.append(epoch_loss_val)\n                self.val_accuracy.append(epoch_acc_val)\n\n            # if epoch % 50 == 0:\n            print(\n                f'{epoch}/{n_epochs} - training_loss: {epoch_loss:.4f}\\t validation_loss: {epoch_loss_val:.4f}\\t validation_accuracy: {epoch_acc_val:.4f}')\n                \n    def plot_losses(self):\n        plt.plot(self.train_losses, label=\"Training loss\")\n        plt.plot(self.val_losses, label=\"Validation loss\")\n        plt.plot(self.val_accuracy, label=\"Validation accuracy\")       \n        plt.legend()\n        plt.title(\"Losses\")\n        plt.show()\n        plt.close()","metadata":{"execution":{"iopub.status.busy":"2022-10-16T21:37:39.916139Z","iopub.execute_input":"2022-10-16T21:37:39.916514Z","iopub.status.idle":"2022-10-16T21:37:39.930708Z","shell.execute_reply.started":"2022-10-16T21:37:39.916476Z","shell.execute_reply":"2022-10-16T21:37:39.929626Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"n_epochs = 500\nlearning_rate = 1e-3\nweight_decay = 1e-6\n\nX_train, X_test, y_train, y_test = train_test_split(samples, targets)\n\ndata_transform = T.Compose([\n    T.ToTensor(),\n    T.Resize((256, 256)),\n    T.ColorJitter(),\n    T.RandomCrop(224),\n    T.RandomHorizontalFlip()\n])\n\ntrain_data = CustomDataset(X_train, y_train, data_transform)\nval_data = CustomDataset(X_test, y_test, None)\n\ntrain_loader = DataLoader(train_data, batch_size=128, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=128, shuffle=True)\n\nmodel = KittenModel().to(device)\n# model = scratch_nn().to(device)\n# loss_fn = nn.BCELoss()\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=0.9)\n\nopt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n\nopt.train(train_loader, val_loader, n_epochs)\nopt.plot_losses()","metadata":{"execution":{"iopub.status.busy":"2022-10-16T21:39:35.627527Z","iopub.execute_input":"2022-10-16T21:39:35.627882Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 147/147 [00:34<00:00,  4.22it/s]\n100%|██████████| 49/49 [00:09<00:00,  5.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"0/500 - training_loss: 0.8131\t validation_loss: 0.8119\t validation_accuracy: 0.5014\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▍      | 51/147 [00:12<00:24,  3.97it/s]","output_type":"stream"}]}]}